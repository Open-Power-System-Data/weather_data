{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; background-color: #D9EDF7\">\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #CFCFCF\">\n",
    "      <b>Weather data: Main notebook</b>\n",
    "      <ul>\n",
    "        <li><a href=\"main.ipynb\">Main Notebook</a></li>\n",
    "        <li>Downloading Notebook</li>\n",
    "        <li><a href=\"documentation.ipynb\">Documentation</a></li>\n",
    "      </ul>\n",
    "      <br>This Notebook is part of the <a href=\"http://data.open-power-system-data.org/weather_data\">Weather data Datapackage</a> of <a href=\"http://open-power-system-data.org\">Open Power System Data</a>.\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Introductory-Notes\" data-toc-modified-id=\"Introductory-Notes-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introductory Notes</a></div><div class=\"lev2 toc-item\"><a href=\"#How-to-use-the-script:\" data-toc-modified-id=\"How-to-use-the-script:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>How to use the script:</a></div><div class=\"lev1 toc-item\"><a href=\"#Script-Setup\" data-toc-modified-id=\"Script-Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Script Setup</a></div><div class=\"lev1 toc-item\"><a href=\"#Download-raw-data\" data-toc-modified-id=\"Download-raw-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Download raw data</a></div><div class=\"lev2 toc-item\"><a href=\"#Input\" data-toc-modified-id=\"Input-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Input</a></div><div class=\"lev3 toc-item\"><a href=\"#Timeframe\" data-toc-modified-id=\"Timeframe-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Timeframe</a></div><div class=\"lev3 toc-item\"><a href=\"#Geography-coordinates\" data-toc-modified-id=\"Geography-coordinates-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Geography coordinates</a></div><div class=\"lev2 toc-item\"><a href=\"#Subsetting-data\" data-toc-modified-id=\"Subsetting-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Subsetting data</a></div><div class=\"lev1 toc-item\"><a href=\"#Downloading-data\" data-toc-modified-id=\"Downloading-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Downloading data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-wind-data\" data-toc-modified-id=\"Get-wind-data-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Get wind data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-roughness-data\" data-toc-modified-id=\"Get-roughness-data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Get roughness data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-radiation-data\" data-toc-modified-id=\"Get-radiation-data-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Get radiation data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-temperature-data\" data-toc-modified-id=\"Get-temperature-data-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Get temperature data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-air-density-data\" data-toc-modified-id=\"Get-air-density-data-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Get air density data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-air-pressure-data\" data-toc-modified-id=\"Get-air-pressure-data-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Get air pressure data</a></div><div class=\"lev2 toc-item\"><a href=\"#Get-lat-and-lon-dimensions\" data-toc-modified-id=\"Get-lat-and-lon-dimensions-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Get lat and lon dimensions</a></div><div class=\"lev2 toc-item\"><a href=\"#Check-the-precision-of-the-downloaded-data\" data-toc-modified-id=\"Check-the-precision-of-the-downloaded-data-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Check the precision of the downloaded data</a></div><div class=\"lev1 toc-item\"><a href=\"#Setting-up-the-DataFrame\" data-toc-modified-id=\"Setting-up-the-DataFrame-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Setting up the DataFrame</a></div><div class=\"lev2 toc-item\"><a href=\"#Converting-the-timeformat-to-ISO-8601\" data-toc-modified-id=\"Converting-the-timeformat-to-ISO-8601-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Converting the timeformat to ISO 8601</a></div><div class=\"lev2 toc-item\"><a href=\"#Converting-wind-vectors-to-wind-speed\" data-toc-modified-id=\"Converting-wind-vectors-to-wind-speed-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Converting wind vectors to wind speed</a></div><div class=\"lev2 toc-item\"><a href=\"#Setting-up-data-Frame-for-roughness,-radiation,-temperature-and-air-parameters\" data-toc-modified-id=\"Setting-up-data-Frame-for-roughness,-radiation,-temperature-and-air-parameters-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Setting up data Frame for roughness, radiation, temperature and air parameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Combining-the-data-Frames\" data-toc-modified-id=\"Combining-the-data-Frames-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Combining the data Frames</a></div><div class=\"lev1 toc-item\"><a href=\"#Structure-the-dataframe,-add-and-remove-columns\" data-toc-modified-id=\"Structure-the-dataframe,-add-and-remove-columns-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Structure the dataframe, add and remove columns</a></div><div class=\"lev2 toc-item\"><a href=\"#Calculating-the-displacement-height\" data-toc-modified-id=\"Calculating-the-displacement-height-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Calculating the displacement height</a></div><div class=\"lev2 toc-item\"><a href=\"#Adding-needed-and-removing-not-needed-columns\" data-toc-modified-id=\"Adding-needed-and-removing-not-needed-columns-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Adding needed and removing not needed columns</a></div><div class=\"lev2 toc-item\"><a href=\"#Renaming-and-sorting-columns\" data-toc-modified-id=\"Renaming-and-sorting-columns-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Renaming and sorting columns</a></div><div class=\"lev2 toc-item\"><a href=\"#First-look-at-the-final-data-Frame\" data-toc-modified-id=\"First-look-at-the-final-data-Frame-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>First look at the final data Frame</a></div><div class=\"lev3 toc-item\"><a href=\"#structure-and-format\" data-toc-modified-id=\"structure-and-format-6.4.1\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>structure and format</a></div><div class=\"lev3 toc-item\"><a href=\"#resulting-dataframe\" data-toc-modified-id=\"resulting-dataframe-6.4.2\"><span class=\"toc-item-num\">6.4.2&nbsp;&nbsp;</span>resulting dataframe</a></div><div class=\"lev1 toc-item\"><a href=\"#Saving-data\" data-toc-modified-id=\"Saving-data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Saving data</a></div><div class=\"lev2 toc-item\"><a href=\"#Save-as-CSV\" data-toc-modified-id=\"Save-as-CSV-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Save as CSV</a></div><div class=\"lev2 toc-item\"><a href=\"#Save-as-SQLite\" data-toc-modified-id=\"Save-as-SQLite-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Save as SQLite</a></div><div class=\"lev2 toc-item\"><a href=\"#Create-metadata\" data-toc-modified-id=\"Create-metadata-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Create metadata</a></div><div class=\"lev2 toc-item\"><a href=\"#Generating-checksums\" data-toc-modified-id=\"Generating-checksums-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Generating checksums</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Introductory Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains code that allows the download, subset and processing of [MERRA-2](http://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/) datasets (provided by NASA Goddard Space Flight Center) and export them as CSV.\n",
    "\n",
    "**Weather data differ significantly from the other data types used resp. provided by OPSD** in that the sheer size of the data packages greatly exceeds OPSD's capacity to host them in a similar way as feed-in timeseries, power plant data etc. While the other data packages also offer a complete one-klick download of the bundled data packages with all relevant data this is impossible for weather datasets like MERRA-2 due to their size (variety of variables, very long timespan, huge geographical coverage etc.). It would make no sense to mirror the data from the NASA servers.\n",
    "\n",
    "Instead we choose to provide only a **documented methodological script**. The  method describes one way to automatically obtain the desired weather data from the MERRA-2 database and simplifies resp. unifies alternative manual data obtaining methods in a single script.\n",
    "\n",
    "**More detailed background information** on weather data can be found in the <a href=\"main.ipynb\">Main notebook</a> and the [OPSD Wiki](https://github.com/Open-Power-System-Data/common/wiki/Information-on-weather-data) on Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "## How to use the script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download MERRA-2 data, you have to **register at NASA earth data portal:**\n",
    "1. Register an account at [https://urs.earthdata.nasa.gov/](https://urs.earthdata.nasa.gov/)\n",
    "2. Go to \"My Applications\" -> \"Approve More Applications\" and add _NASA GESDISC DATA ARCHIVE_ (scroll down list)\n",
    "3. Input your username and password when requested by the script\n",
    "\n",
    "_Hints:_\n",
    "* _Be aware that by registering you are \"consenting to complete monitoring with no expectation of privacy\"..._\n",
    "* _It seems that the routine sometimes has problems with usernames which include upper case letters - avoid them if you can._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Script Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:08:34.066581",
     "start_time": "2017-07-05T19:08:31.685713"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import requests\n",
    "import logging\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "import sqlalchemy\n",
    "\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "from opendap_download.multi_processing_download import DownloadManager\n",
    "import math\n",
    "from functools import partial\n",
    "import re\n",
    "import getpass\n",
    "from datetime import datetime, timedelta\n",
    "import dateutil.parser\n",
    "\n",
    "# Set up a log\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Download raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part defines the input parameters according to the user and creates an URL that can download the desired MERRA-2 data via the OPeNDAP interface (see <a href=\"documentation.ipynb\">documentation notebook</a> for information on OPeNDAP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of desired timespan the data is needed for. (only complete years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:08:40.156966",
     "start_time": "2017-07-05T19:08:40.147943"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User input of timespan\n",
    "download_year = 2016\n",
    "\n",
    "# Create the start date 2016-01-01\n",
    "download_start_date = str(download_year) + '-01-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geography coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of desired coordinates. The user has to input two corner coordinates \n",
    "of a rectangular area (Format WGS84, decimal system).\n",
    "* Northeast coordinate: lat_1, lon_1\n",
    "* Southwest coordinate: lat_2, lon_2\n",
    "\n",
    "The area/coordinates will be converted from lat/lon to the MERRA-2 grid coordinates.\n",
    "Since the resolution of the MERRA-2 grid is 0.5 x 0.625°, the given exact coordinates will \n",
    "matched as close as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:08:49.864174",
     "start_time": "2017-07-05T19:08:49.747867"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# User input of coordinates\n",
    "# ------\n",
    "# Example: Germany (lat/lon)\n",
    "# Northeastern point: 55.05917°N, 15.04361°E\n",
    "# Southwestern point: 47.27083°N, 5.86694°E\n",
    "\n",
    "# It is important to make the southwestern coordinate lat_1 and lon_1 since\n",
    "# the MERRA-2 portal requires it!\n",
    "# Southwestern coordinate\n",
    "# lat_1, lon_1 = 47.27083, 5.86694 Germany\n",
    "# Northeastern coordinate \n",
    "# lat_2, lon_2 = 55.05917, 15.04361 Germany\n",
    "\n",
    "# Southwestern coordinate\n",
    "lat_1, lon_1 = 47.27083, 5.86694\n",
    "# Northeastern coordinate\n",
    "lat_2, lon_2 = 55.05917, 15.04361\n",
    "\n",
    "def translate_lat_to_geos5_native(latitude):\n",
    "    \"\"\"\n",
    "    The source for this formula is in the MERRA2 \n",
    "    Variable Details - File specifications for GEOS pdf file.\n",
    "    The Grid in the documentation has points from 1 to 361 and 1 to 576.\n",
    "    The MERRA-2 Portal uses 0 to 360 and 0 to 575.\n",
    "    latitude: float Needs +/- instead of N/S\n",
    "    \"\"\"\n",
    "    return ((latitude + 90) / 0.5)\n",
    "\n",
    "def translate_lon_to_geos5_native(longitude):\n",
    "    \"\"\"See function above\"\"\"\n",
    "    return ((longitude + 180) / 0.625)\n",
    "\n",
    "def find_closest_coordinate(calc_coord, coord_array):\n",
    "    \"\"\"\n",
    "    Since the resolution of the grid is 0.5 x 0.625, the 'real world'\n",
    "    coordinates will not be matched 100% correctly. This function matches \n",
    "    the coordinates as close as possible. \n",
    "    \"\"\"\n",
    "    # np.argmin() finds the smallest value in an array and returns its\n",
    "    # index. np.abs() returns the absolute value of each item of an array.\n",
    "    # To summarize, the function finds the difference closest to 0 and returns \n",
    "    # its index. \n",
    "    index = np.abs(coord_array-calc_coord).argmin()\n",
    "    return coord_array[index]\n",
    "\n",
    "# The arrays contain the coordinates of the grid used by the API.\n",
    "# The values are from 0 to 360 and 0 to 575\n",
    "lat_coords = np.arange(0, 361, dtype=int)\n",
    "lon_coords = np.arange(0, 576, dtype=int)\n",
    "\n",
    "# Translate the coordinates that define your area to grid coordinates.\n",
    "lat_coord_1 = translate_lat_to_geos5_native(lat_1)\n",
    "lon_coord_1 = translate_lon_to_geos5_native(lon_1)\n",
    "lat_coord_2 = translate_lat_to_geos5_native(lat_2)\n",
    "lon_coord_2 = translate_lon_to_geos5_native(lon_2)\n",
    "\n",
    "\n",
    "# Find the closest coordinate in the grid.\n",
    "lat_co_1_closest = find_closest_coordinate(lat_coord_1, lat_coords)\n",
    "lon_co_1_closest = find_closest_coordinate(lon_coord_1, lon_coords)\n",
    "lat_co_2_closest = find_closest_coordinate(lat_coord_2, lat_coords)\n",
    "lon_co_2_closest = find_closest_coordinate(lon_coord_2, lon_coords)\n",
    "\n",
    "# Check the precision of the grid coordinates. These coordinates are not lat/lon. \n",
    "# They are coordinates on the MERRA-2 grid. \n",
    "log.info('Calculated coordinates for point 1: ' + str((lat_coord_1, lon_coord_1)))\n",
    "log.info('Closest coordinates for point 1: ' + str((lat_co_1_closest, lon_co_1_closest)))\n",
    "log.info('Calculated coordinates for point 2: ' + str((lat_coord_2, lon_coord_2)))\n",
    "log.info('Closest coordinates for point 2: ' + str((lat_co_2_closest, lon_co_2_closest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Subsetting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Combining parameter choices above/translation according to OPenDAP guidelines into URL-appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:08:56.233786",
     "start_time": "2017-07-05T19:08:56.111463"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def translate_year_to_file_number(year):\n",
    "    \"\"\"\n",
    "    The file names consist of a number and a meta data string. \n",
    "    The number changes over the years. 1980 until 1991 it is 100, \n",
    "    1992 until 2000 it is 200, 2001 until 2010 it is  300 \n",
    "    and from 2011 until now it is 400.\n",
    "    \"\"\"\n",
    "    file_number = ''\n",
    "    \n",
    "    if year >= 1980 and year < 1992:\n",
    "        file_number = '100'\n",
    "    elif year >= 1992 and year < 2001:\n",
    "        file_number = '200'\n",
    "    elif year >= 2001 and year < 2011:\n",
    "        file_number = '300'\n",
    "    elif year >= 2011:\n",
    "        file_number = '400'\n",
    "    else:\n",
    "        raise Exception('The specified year is out of range.')\n",
    "    \n",
    "    return file_number\n",
    "    \n",
    "\n",
    "\n",
    "def generate_url_params(parameter, time_para, lat_para, lon_para):\n",
    "    \"\"\"Creates a string containing all the parameters in query form\"\"\"\n",
    "    parameter = map(lambda x: x + time_para, parameter)\n",
    "    parameter = map(lambda x: x + lat_para, parameter)\n",
    "    parameter = map(lambda x: x + lon_para, parameter)\n",
    "    \n",
    "    return ','.join(parameter)\n",
    "    \n",
    "    \n",
    "\n",
    "def generate_download_links(download_years, base_url, dataset_name, url_params):\n",
    "    \"\"\"\n",
    "    Generates the links for the download. \n",
    "    download_years: The years you want to download as array. \n",
    "    dataset_name: The name of the data set. For example tavg1_2d_slv_Nx\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    for y in download_years: \n",
    "    # build the file_number\n",
    "        y_str = str(y)\n",
    "        file_num = translate_year_to_file_number(download_year)\n",
    "        for m in range(1,13):\n",
    "            # build the month string: for the month 1 - 9 it starts with a leading 0. \n",
    "            # zfill solves that problem\n",
    "            m_str = str(m).zfill(2)\n",
    "            # monthrange returns the first weekday and the number of days in a \n",
    "            # month. Also works for leap years.\n",
    "            _, nr_of_days = monthrange(y, m)\n",
    "            for d in range(1,nr_of_days+1):\n",
    "                d_str = str(d).zfill(2)\n",
    "                # Create the file name string\n",
    "                file_name = 'MERRA2_{num}.{name}.{y}{m}{d}.nc4'.format(\n",
    "                    num=file_num, name=dataset_name, \n",
    "                    y=y_str, m=m_str, d=d_str)\n",
    "                # Create the query\n",
    "                query = '{base}{y}/{m}/{name}.nc4?{params}'.format(\n",
    "                    base=base_url, y=y_str, m=m_str, \n",
    "                    name=file_name, params=url_params)\n",
    "                urls.append(query)\n",
    "    return urls\n",
    "\n",
    "requested_params = ['U2M', 'U10M', 'U50M', 'V2M', 'V10M', 'V50M', 'DISPH']\n",
    "requested_time = '[0:1:23]'\n",
    "# Creates a string that looks like [start:1:end]. start and end are the lat or\n",
    "# lon coordinates define your area.\n",
    "requested_lat = '[{lat_1}:1:{lat_2}]'.format(\n",
    "                lat_1=lat_co_1_closest, lat_2=lat_co_2_closest)\n",
    "requested_lon = '[{lon_1}:1:{lon_2}]'.format(\n",
    "                lon_1=lon_co_1_closest, lon_2=lon_co_2_closest)\n",
    "\n",
    "\n",
    "\n",
    "parameter = generate_url_params(requested_params, requested_time,\n",
    "                                requested_lat, requested_lon)\n",
    "\n",
    "BASE_URL = 'https://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXSLV.5.12.4/'\n",
    "generated_URL = generate_download_links([download_year], BASE_URL, \n",
    "                                        'tavg1_2d_slv_Nx', \n",
    "                                        parameter)\n",
    "            \n",
    "# See what a query to the MERRA-2 portal looks like.        \n",
    "log.info(generated_URL[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part subsequently downloads the subsetted raw data from the MERRA-2-datasets. \n",
    "The download process is outsourced from the notebook, because it is a standard and repetitive process. If you are interested in the the code, see the [opendap_download module](opendap_download/).\n",
    "\n",
    "_Note: Each of the following steps to download the data will take a few minutes, depending on the size of geographical area and amount of data (the total download routine e.G. for Germany takes roughly 70 minutes)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get wind data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters from the dataset [tavg1_2d_slv_Nx (M2T1NXSLV)](http://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXSLV.5.12.4/contents.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:19:19.577626",
     "start_time": "2017-07-05T19:09:11.208420"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download data (one file per day and dataset) with links to local directory.\n",
    "# Username and password for MERRA-2 (NASA earthdata portal)\n",
    "username = input('Username: ')\n",
    "password = getpass.getpass('Password:')\n",
    "\n",
    "# The DownloadManager is able to download files. If you have a fast internet \n",
    "# connection, setting this to 2 is enough. If you have slow wifi, try setting\n",
    "# it to 4 or 5. If you download too fast, the data portal might ban you for a \n",
    "# day. \n",
    "NUMBER_OF_CONNECTIONS = 5\n",
    "\n",
    "# The DownloadManager class is defined in the opendap_download module. \n",
    "download_manager = DownloadManager()\n",
    "download_manager.set_username_and_password(username, password)\n",
    "download_manager.download_path = 'download_wind'\n",
    "download_manager.download_urls = generated_URL\n",
    "\n",
    "# If you want to see the download progress, check the download folder you \n",
    "# specified\n",
    "%time download_manager.start_download(NUMBER_OF_CONNECTIONS)\n",
    "\n",
    "# Download time approx. 20+ min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get roughness data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters from the dataset [tavg1_2d_rad_Nx (M2T1NXRAD)](https://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXRAD.5.12.4/contents.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:25:32.163166",
     "start_time": "2017-07-05T19:19:19.577626"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Roughness data is in a different data set. The parameter is called Z0M. \n",
    "roughness_para = generate_url_params(['Z0M'], requested_time, \n",
    "                                     requested_lat, requested_lon)\n",
    "ROUGHNESS_BASE_URL = 'https://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXFLX.5.12.4/'\n",
    "roughness_links = generate_download_links([download_year], ROUGHNESS_BASE_URL,\n",
    "                                          'tavg1_2d_flx_Nx', roughness_para)\n",
    "\n",
    "download_manager.download_path = 'download_roughness'\n",
    "download_manager.download_urls = roughness_links\n",
    "\n",
    "# If you want to see the download progress, check the download folder you \n",
    "# specified.\n",
    "%time download_manager.start_download(NUMBER_OF_CONNECTIONS)\n",
    "\n",
    "# Download time approx. 12+ min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get radiation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters from the dataset [tavg1_2d_flx_Nx (M2T1NXFLX)](http://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXFLX.5.12.4/contents.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:30:15.480181",
     "start_time": "2017-07-05T19:25:32.170186"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters SWGDN and SWTDN\n",
    "radiation_para = generate_url_params(['SWGDN', 'SWTDN'], requested_time, \n",
    "                                     requested_lat, requested_lon)\n",
    "RADIATION_BASE_URL = 'https://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXRAD.5.12.4/'\n",
    "radiation_links = generate_download_links([download_year], RADIATION_BASE_URL, \n",
    "                                         'tavg1_2d_rad_Nx', radiation_para)\n",
    "\n",
    "download_manager.download_path = 'download_radiation'\n",
    "download_manager.download_urls = radiation_links\n",
    "\n",
    "%time download_manager.start_download(NUMBER_OF_CONNECTIONS)\n",
    "\n",
    "# Download time approx. 8+ min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters from the dataset [tavg1_2d_slv_Nx (M2T1NXSLV)](http://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXSLV.5.12.4/contents.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:37:42.740556",
     "start_time": "2017-07-05T19:30:15.486197"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter T2M (i.e. the temperature 2 meters above displacement height)\n",
    "temperature_para = generate_url_params(['T2M'], requested_time, \n",
    "                                     requested_lat, requested_lon)\n",
    "TEMPERATURE_BASE_URL = 'http://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXSLV.5.12.4/'\n",
    "temperature_links = generate_download_links([download_year], TEMPERATURE_BASE_URL, \n",
    "                                         'tavg1_2d_slv_Nx', temperature_para)\n",
    "\n",
    "download_manager.download_path = 'download_temperature'\n",
    "download_manager.download_urls = temperature_links\n",
    "\n",
    "%time download_manager.start_download(NUMBER_OF_CONNECTIONS)\n",
    "\n",
    "# Download time approx. 13+ min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get air density data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters from the dataset [tavg1_2d_flx_Nx (M2T1NXFLX)](http://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXFLX.5.12.4/contents.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:45:02.911206",
     "start_time": "2017-07-05T19:37:42.749574"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter RHOA\n",
    "density_para = generate_url_params(['RHOA'], requested_time, \n",
    "                                     requested_lat, requested_lon)\n",
    "DENSITY_BASE_URL = 'http://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXFLX.5.12.4/'\n",
    "density_links = generate_download_links([download_year], DENSITY_BASE_URL, \n",
    "                                         'tavg1_2d_flx_Nx', density_para)\n",
    "\n",
    "download_manager.download_path = 'download_density'\n",
    "download_manager.download_urls = density_links\n",
    "\n",
    "%time download_manager.start_download(NUMBER_OF_CONNECTIONS)\n",
    "\n",
    "# Download time approx. 13+ min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get air pressure data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters from the dataset [tavg1_2d_slv_Nx (M2T1NXSLV)](http://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXSLV.5.12.4/contents.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:52:19.832091",
     "start_time": "2017-07-05T19:45:02.911206"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters PS\n",
    "pressure_para = generate_url_params(['PS'], requested_time, \n",
    "                                     requested_lat, requested_lon)\n",
    "PRESSURE_BASE_URL = 'http://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXSLV.5.12.4/'\n",
    "pressure_links = generate_download_links([download_year], PRESSURE_BASE_URL, \n",
    "                                         'tavg1_2d_slv_Nx', pressure_para)\n",
    "\n",
    "download_manager.download_path = 'download_pressure'\n",
    "download_manager.download_urls = pressure_links\n",
    "\n",
    "%time download_manager.start_download(NUMBER_OF_CONNECTIONS)\n",
    "\n",
    "# Download time approx. 15+ min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get lat and lon dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the dataset only has MERRA-2 grid coordinates. To translate the points\n",
    "back to \"real world\" coordinates, the data portal offers a dimension scale file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:56:49.202588",
     "start_time": "2017-07-05T19:56:45.345723"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The dimensions map the MERRA2 grid coordinates to lat/lon. The coordinates \n",
    "# to request are 0:360 wheare as the other coordinates are 1:361\n",
    "requested_lat_dim = '[{lat_1}:1:{lat_2}]'.format(\n",
    "                    lat_1=lat_co_1_closest, lat_2=lat_co_2_closest)\n",
    "requested_lon_dim = '[{lon_1}:1:{lon_2}]'.format(\n",
    "                    lon_1=lon_co_1_closest , lon_2=lon_co_2_closest )\n",
    "\n",
    "lat_lon_dimension_para = 'lat' + requested_lat_dim + ',lon' + requested_lon_dim\n",
    "\n",
    "# Creating the download url.\n",
    "dimension_url = 'https://goldsmr4.sci.gsfc.nasa.gov/opendap/MERRA2/M2T1NXSLV.5.12.4/2014/01/MERRA2_400.tavg1_2d_slv_Nx.20140101.nc4.nc4?'\n",
    "dimension_url = dimension_url + lat_lon_dimension_para\n",
    "download_manager.download_path = 'dimension_scale'\n",
    "download_manager.download_urls = [dimension_url]\n",
    "\n",
    "# Since the dimension is only one file, we only need one connection. \n",
    "%time download_manager.start_download(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the precision of the downloaded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the back and forth conversion from \"real world\" coordinates to MERRA-2 grid points,\n",
    "this part helps you to check if the conversion was precise enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:56:50.141524",
     "start_time": "2017-07-05T19:56:49.941997"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join('dimension_scale', DownloadManager.get_filename(\n",
    "        dimension_url))\n",
    "\n",
    "with xr.open_dataset(file_path) as ds_dim:\n",
    "    df_dim = ds_dim.to_dataframe()\n",
    "\n",
    "lat_array = ds_dim['lat'].data.tolist()\n",
    "lon_array = ds_dim['lon'].data.tolist()\n",
    "\n",
    "# The log output helps evaluating the precision of the received data.\n",
    "log.info('Requested lat: ' + str((lat_1, lat_2)))\n",
    "log.info('Received lat: ' + str(lat_array))\n",
    "log.info('Requested lon: ' + str((lon_1, lon_2)))\n",
    "log.info('Received lon: ' + str(lon_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setting up the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part sets up a DataFrame and reads the raw data into it. First the wind data and adding the remaining data afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:57:11.379096",
     "start_time": "2017-07-05T19:57:01.242313"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_date(data_set):\n",
    "    \"\"\"\n",
    "    Extracts the date from the filename before merging the datasets. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The attribute name changed during the development of this script\n",
    "        # from HDF5_Global.Filename to Filename. \n",
    "        if 'HDF5_GLOBAL.Filename' in data_set.attrs:\n",
    "            f_name = data_set.attrs['HDF5_GLOBAL.Filename']\n",
    "        elif 'Filename' in data_set.attrs:\n",
    "            f_name = data_set.attrs['Filename']\n",
    "        else: \n",
    "            raise AttributeError('The attribute name has changed again!')\n",
    "        \n",
    "        # find a match between \".\" and \".nc4\" that does not have \".\" .\n",
    "        exp = r'(?<=\\.)[^\\.]*(?=\\.nc4)'\n",
    "        res = re.search(exp, f_name).group(0)\n",
    "        # Extract the date. \n",
    "        y, m, d = res[0:4], res[4:6], res[6:8]\n",
    "        date_str = ('%s-%s-%s' % (y, m, d))\n",
    "        data_set = data_set.assign(date=date_str)\n",
    "        return data_set\n",
    "\n",
    "    except KeyError:\n",
    "        # The last dataset is the one all the other sets will be merged into. \n",
    "        # Therefore, no date can be extracted.\n",
    "        return data_set\n",
    "        \n",
    "\n",
    "file_path = os.path.join('download_wind', '*.nc4')\n",
    "\n",
    "try:\n",
    "    with xr.open_mfdataset(file_path, concat_dim='date',\n",
    "                           preprocess=extract_date) as ds_wind:\n",
    "        print(ds_wind)\n",
    "        df_wind = ds_wind.to_dataframe()\n",
    "        \n",
    "except xr.MergeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:57:11.576594",
     "start_time": "2017-07-05T19:57:11.383085"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wind.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T19:58:54.443971",
     "start_time": "2017-07-05T19:57:14.121877"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_date = datetime.strptime(download_start_date, '%Y-%m-%d')\n",
    "\n",
    "def calculate_datetime(d_frame):\n",
    "    \"\"\"\n",
    "    Calculates the accumulated hour based on the date.\n",
    "    \"\"\"\n",
    "    cur_date = datetime.strptime(d_frame['date'], '%Y-%m-%d')\n",
    "    hour = int(d_frame['time'])\n",
    "    delta = abs(cur_date - start_date).days\n",
    "    date_time_value = (delta * 24) + (hour)\n",
    "    return date_time_value\n",
    "\n",
    "\n",
    "df_wind['date_time_hours'] = df_wind.apply(calculate_datetime, axis=1)\n",
    "df_wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the timeformat to ISO 8601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:02:23.077220",
     "start_time": "2017-07-05T19:58:54.445977"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def converting_timeformat_to_ISO8601(row):\n",
    "    \"\"\"Generates datetime according to ISO 8601 (UTC)\"\"\"\n",
    "    date = dateutil.parser.parse(row['date'])\n",
    "    hour = int(row['time'])\n",
    "    # timedelta from the datetime module enables the programmer \n",
    "    # to add time to a date. \n",
    "    date_time = date + timedelta(hours = hour)\n",
    "    return str(date_time.isoformat()) + 'Z'  # MERRA2 datasets have UTC time zone.\n",
    "df_wind['date_utc'] = df_wind.apply(converting_timeformat_to_ISO8601, axis=1)\n",
    "\n",
    "df_wind['date_utc']\n",
    "\n",
    "# execution time approx. 3+ min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting wind vectors to wind speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part uses the given wind vectors in the MERRA-2 original data to calculate a wind speed (vector addition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:06:12.987618",
     "start_time": "2017-07-05T20:02:23.079229"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_windspeed(d_frame, idx_u, idx_v):\n",
    "    \"\"\"\n",
    "    Calculates the windspeed. The returned unit is m/s\n",
    "    \"\"\"\n",
    "    um = float(d_frame[idx_u])\n",
    "    vm = float(d_frame[idx_v])\n",
    "    speed = math.sqrt((um ** 2) + (vm ** 2))\n",
    "    return round(speed, 2)\n",
    "\n",
    "# partial is used to create a function with pre-set arguments. \n",
    "calc_windspeed_2m = partial(calculate_windspeed, idx_u='U2M', idx_v='V2M')\n",
    "calc_windspeed_10m = partial(calculate_windspeed, idx_u='U10M', idx_v='V10M')\n",
    "calc_windspeed_50m = partial(calculate_windspeed, idx_u='U50M', idx_v='V50M')\n",
    "\n",
    "df_wind['v_2m'] = df_wind.apply(calc_windspeed_2m, axis=1)\n",
    "df_wind['v_10m']= df_wind.apply(calc_windspeed_10m, axis=1)\n",
    "df_wind['v_50m'] = df_wind.apply(calc_windspeed_50m, axis=1)\n",
    "df_wind\n",
    "\n",
    "# execution time approx. 3 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up data Frame for roughness, radiation, temperature and air parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:07:49.977393",
     "start_time": "2017-07-05T20:07:45.887270"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join('download_roughness', '*.nc4')\n",
    "with xr.open_mfdataset(file_path, concat_dim='date', \n",
    "                       preprocess=extract_date) as ds_rough:\n",
    "    df_rough = ds_rough.to_dataframe()\n",
    "\n",
    "df_rough.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:07:55.300506",
     "start_time": "2017-07-05T20:07:49.978395"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join('download_radiation', '*.nc4')\n",
    "try:\n",
    "    with xr.open_mfdataset(file_path, concat_dim='date',\n",
    "                           preprocess=extract_date) as ds_rad:\n",
    "        print(ds_rad)\n",
    "        df_rad = ds_rad.to_dataframe()\n",
    "\n",
    "except xr.MergeError as e:\n",
    "    print(e)\n",
    "df_rad.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:07:59.487112",
     "start_time": "2017-07-05T20:07:55.301510"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join('download_temperature', '*.nc4')\n",
    "try:\n",
    "    with xr.open_mfdataset(file_path, concat_dim='date',\n",
    "                           preprocess=extract_date) as ds_temp:\n",
    "        print(ds_temp)\n",
    "        df_temp = ds_temp.to_dataframe()\n",
    "\n",
    "except xr.MergeError as e:\n",
    "    print(e)\n",
    "df_temp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:08:03.661984",
     "start_time": "2017-07-05T20:07:59.488116"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join('download_density', '*.nc4')\n",
    "try:\n",
    "    with xr.open_mfdataset(file_path, concat_dim='date',\n",
    "                           preprocess=extract_date) as ds_dens:\n",
    "        print(ds_dens)\n",
    "        df_dens = ds_dens.to_dataframe()\n",
    "\n",
    "except xr.MergeError as e:\n",
    "    print(e)\n",
    "df_dens.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:08:08.196582",
     "start_time": "2017-07-05T20:08:03.662961"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join('download_pressure', '*.nc4')\n",
    "try:\n",
    "    with xr.open_mfdataset(file_path, concat_dim='date',\n",
    "                           preprocess=extract_date) as ds_pres:\n",
    "        print(ds_pres)\n",
    "        df_pres = ds_pres.to_dataframe()\n",
    "\n",
    "except xr.MergeError as e:\n",
    "    print(e)\n",
    "df_pres.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Combining the data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:08:14.554442",
     "start_time": "2017-07-05T20:08:08.198587"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df_wind, df_rough, on=['date', 'lat', 'lon', 'time'])\n",
    "df = pd.merge(df, df_rad, on=['date', 'lat', 'lon', 'time'])\n",
    "df = pd.merge(df, df_temp, on=['date', 'lat', 'lon', 'time'])\n",
    "df = pd.merge(df, df_dens, on=['date', 'lat', 'lon', 'time'])\n",
    "df = pd.merge(df, df_pres, on=['date', 'lat', 'lon', 'time'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Structure the dataframe, add and remove columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the displacement height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The so-called \"displacement height\" is the height\n",
    "> _\"[...] at which zero wind speed is achieved as a result of flow obstacles such as trees or buildings. It is generally approximated as 2/3 of the average height of the obstacles. For example, if estimating winds over a forest canopy of height h = 30 m, the zero-plane displacement would be d = 20 m.\"_ ([Source](https://en.wikipedia.org/wiki/Log_wind_profile#Definition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:23:10.533218",
     "start_time": "2017-07-05T20:21:45.412045"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate height for h1 (displacement height +2m) and h2 (displacement height\n",
    "# +10m).\n",
    "df['h1'] = df.apply((lambda x:int(x['DISPH']) + 2), axis=1)\n",
    "df['h2'] = df.apply((lambda x:int(x['DISPH']) + 10), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding needed and removing not needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:23:13.000898",
     "start_time": "2017-07-05T20:23:10.534193"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('DISPH', axis=1, inplace=True)\n",
    "df.drop(['time', 'date'], axis=1, inplace=True)\n",
    "df.drop(['U2M', 'U10M', 'U50M', 'V2M', 'V10M', 'V50M'], axis=1, inplace=True)\n",
    "\n",
    "df['lat'] = df['lat'].apply(lambda x: lat_array[int(x)])\n",
    "df['lon'] = df['lon'].apply(lambda x: lon_array[int(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming and sorting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:23:13.422342",
     "start_time": "2017-07-05T20:23:13.001904"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rename_map = {'date_time_hours': 'cumulated hours', \n",
    "              'date_utc': 'timestamp',\n",
    "              'v_2m': 'v1', \n",
    "              'v_10m': 'v2', \n",
    "              'Z0M': 'z0',\n",
    "              'T2M': 'T',\n",
    "              'RHOA': 'rho',\n",
    "              'PS': 'p'\n",
    "             }\n",
    "\n",
    "df.rename(columns=rename_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:23:13.568401",
     "start_time": "2017-07-05T20:23:13.425351"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change order of the columns\n",
    "columns = ['timestamp', 'cumulated hours', 'lat', 'lon',\n",
    "        'v1', 'v2', 'v_50m',\n",
    "        'h1', 'h2', 'z0', 'SWTDN', 'SWGDN', 'T', 'rho', 'p']\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the final data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### structure and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:23:13.592465",
     "start_time": "2017-07-05T20:23:13.571409"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:23:13.742866",
     "start_time": "2017-07-05T20:23:13.594471"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:26:04.782036",
     "start_time": "2017-07-05T20:25:19.746858"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('weather_data_GER_2016.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:27:12.761251",
     "start_time": "2017-07-05T20:26:04.784042"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write the results to sqlite database. Using the chunksize parameter makes\n",
    "# this cell not use so much memory. If the parameter is not set, the to_sql\n",
    "# function will try to write all rows at the same time. This uses too much\n",
    "# memory. If you have a lot of memory, you can remove the parameter or increase\n",
    "# it to speed this process up. If you have memory problemes, try decreasing the\n",
    "# chunksize.\n",
    "engine = sqlalchemy.create_engine(\n",
    "    'sqlite:///' + 'weather_data_GER_2016.sqlite')  \n",
    "\n",
    "df.to_sql('weather_data_GER_2016',\n",
    "             engine,\n",
    "             if_exists=\"replace\",\n",
    "             chunksize=100000,\n",
    "             index=False\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:27:24.988898",
     "start_time": "2017-07-05T20:27:24.824468"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we define meta data of the resulting data package.\n",
    "# The meta data follows the specification at:\n",
    "# http://dataprotocols.org/data-packages/\n",
    "\n",
    "metadata = \"\"\"\n",
    "name: opsd-weather-data\n",
    "title: Weather data\n",
    "long_description: >-\n",
    "    Weather data differ significantly from the other data types used resp. \n",
    "    provided by OPSD in that the sheer size of the data packages greatly \n",
    "    exceeds OPSD's capacity to host them in a similar way as feed-in \n",
    "    timeseries, power plant data etc. While the other data packages also\n",
    "    offer a complete one-klick download of the bundled data packages with \n",
    "    all relevant data this is impossible for weather datasets like MERRA-2 due \n",
    "    to their size (variety of variables, very long timespan, huge geographical\n",
    "    coverage etc.). It would make no sense to mirror the data from the NASA \n",
    "    servers.\n",
    "    Instead we choose to provide a documented methodological script \n",
    "    (as a kind of tutorial). The method describes one way to automatically \n",
    "    obtain the desired weather data from the MERRA-2 database and simplifies \n",
    "    resp. unifies alternative manual data obtaining methods in a single \n",
    "    script.\n",
    "    It is recommended to study the the \"Step-by-step user guide\" (developer use \n",
    "    case) on this platform to learn how to run the script.\n",
    "    The data package contains a sample dataset for Germany and the year 2016\n",
    "version: \"2017-07-03\"\n",
    "keywords: [Open Power System Data, MERRA-2, wind, solar, temperature, density, \n",
    "            pressure]\n",
    "geographical-scope: Worldwide (German sample dataset for 2016)\n",
    "description: Script for the download of MERRA-2 weather data\n",
    "resources:\n",
    "    - path: weather_data_GER_2016.csv\n",
    "      format: csv\n",
    "      encoding: UTF-8\n",
    "      schema:         \n",
    "        fields:\n",
    "            - name: timestamp\n",
    "              type: date-time\n",
    "              format: YYYY-MM-DDTHH:MM:SSZ\n",
    "              description: Start of timeperiod in Coordinated Universal Time\n",
    "            - name: cumulated hours\n",
    "              type: number\n",
    "              format: integer\n",
    "              description: summarized number of hours for the timeperiod of the dataset\n",
    "            - name: lat\n",
    "              type: geopoint\n",
    "              format: lat\n",
    "              description: Latitude coordinates\n",
    "            - name: lon\n",
    "              type: geopoint\n",
    "              format: lon\n",
    "              description: Longitude coordinates\n",
    "            - name: v1\n",
    "              type: number\n",
    "              format: float\n",
    "              description: wind speed 2 meters above displacement height\n",
    "            - name: v2\n",
    "              type: number\n",
    "              format: float\n",
    "              description: wind speed 10 meters above displacement height\n",
    "            - name: v_50m\n",
    "              type: number\n",
    "              format: float\n",
    "              description: wind speed 50 meters above ground\n",
    "            - name: h1\n",
    "              type: number\n",
    "              format: float\n",
    "              description: height above ground corresponding to v1\n",
    "            - name: h2\n",
    "              type: number\n",
    "              format: integer\n",
    "              description: height above ground corresponding to v2\n",
    "            - name: z0\n",
    "              type: number\n",
    "              format: integer\n",
    "              description: roughness length\n",
    "            - name: SWTDN\n",
    "              type: number\n",
    "              format: float\n",
    "              description: total top-of-the-atmosphere horizontal radiation\n",
    "            - name: SWGDN\n",
    "              type: number\n",
    "              format: float\n",
    "              description: total ground horizontal radiation\n",
    "            - name: T\n",
    "              type: number\n",
    "              format: float\n",
    "              description: Temperature 2 meters above displacement height\n",
    "            - name: rho\n",
    "              type: number\n",
    "              format: float\n",
    "              description: air density at surface\n",
    "            - name: p\n",
    "              type: number\n",
    "              format: float\n",
    "              description: air pressure at surface\n",
    "            \n",
    "licenses:\n",
    "    - type: MIT license\n",
    "      url: http://www.opensource.org/licenses/MIT\n",
    "sources:\n",
    "    - name: MERRA-2 \n",
    "      web: https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/\n",
    "      source: National Aeronautics and Space Administration - Goddard Space Flight Center\n",
    "contributors:\n",
    "    - name: Martin Jahn\n",
    "      email: martin.jahn@uni-flensburg.de\n",
    "    - name: Jan Urbansky\n",
    "\n",
    "views: True\n",
    "documentation: https://github.com/Open-Power-System-Data/weather_data/blob/2017-07-05/main.ipynb\n",
    "last_changes: corrected typos, slight modifications (file names)\n",
    "\"\"\"\n",
    "\n",
    "metadata = yaml.load(metadata)\n",
    "\n",
    "datapackage_json = json.dumps(metadata, indent=4, separators=(',', ': '))\n",
    "\n",
    "with open('datapackage.json', 'w') as f:\n",
    "    f.write(datapackage_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating checksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-05T20:27:30.104691",
     "start_time": "2017-07-05T20:27:28.101209"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sha_hash(path, blocksize=65536):\n",
    "    sha_hasher = hashlib.sha256()\n",
    "    with open(path, 'rb') as f:\n",
    "        buffer = f.read(blocksize)\n",
    "        while len(buffer) > 0:\n",
    "            sha_hasher.update(buffer)\n",
    "            buffer = f.read(blocksize)\n",
    "        return sha_hasher.hexdigest()\n",
    "\n",
    "\n",
    "output_path = ''\n",
    "\n",
    "files = [\n",
    "    'weather_data_GER_2016.csv',\n",
    "    'weather_data_GER_2016.sqlite']\n",
    "\n",
    "with open(os.path.join(output_path, 'checksums.txt'), 'w') as f:\n",
    "    for file_name in files:\n",
    "        file_hash = get_sha_hash(os.path.join(output_path, file_name))\n",
    "        f.write('{},{}\\n'.format(file_name, file_hash))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
